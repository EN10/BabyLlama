# BabyLlama

Train and run a small [Llama 2](https://ai.meta.com/llama/) model from scratch on the [TinyStories](https://huggingface.co/datasets/roneneldan/TinyStories) dataset.

* [Based on karpathy/llama2.c](https://github.com/karpathy/llama2.c)
* [Based on eniompw/DisneyGPT](https://github.com/eniompw/DisneyGPT)

### [Baby Llama 4k on Colab](https://github.com/EN10/BabyLlama/blob/main/Baby_Llama_4K.ipynb)
#### [Baby Llama 32k on Colab](https://github.com/EN10/BabyLlama/blob/main/Baby_Llama_32K.ipynb)

* [training](https://github.com/karpathy/llama2.c#training)
* [models](https://github.com/karpathy/llama2.c#models)
* [Pretokenized TinyStories](https://huggingface.co/datasets/enio/TinyStories)

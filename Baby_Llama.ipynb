{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMpnnc03TDh6",
        "outputId": "b42cbd0e-fc51-47e4-cb2d-8cc9fb697b2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama2.c'...\n",
            "remote: Enumerating objects: 1434, done.\u001b[K\n",
            "remote: Total 1434 (delta 0), reused 0 (delta 0), pack-reused 1434\u001b[K\n",
            "Receiving objects: 100% (1434/1434), 1.17 MiB | 24.92 MiB/s, done.\n",
            "Resolving deltas: 100% (871/871), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/karpathy/llama2.c.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Udnkv5KTkN8",
        "outputId": "3d5fb792-d4dd-43e9-b399-f3b5790252d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.3 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i98xFBYTQBt"
      },
      "outputs": [],
      "source": [
        "# runtime 100s\n",
        "!cd llama2.c && python tinystories.py download\n",
        "# pretokenize is very slow so use 2 files\n",
        "!cd ./llama2.c/data/TinyStories_all_data/ && rm data{03..49}.json\n",
        "# runtime 100s\n",
        "!cd llama2.c && python tinystories.py pretokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# or download pretokenized\n",
        "!mkdir -p /content/llama2.c/data/TinyStories_all_data/\n",
        "!cd ./llama2.c/data/TinyStories_all_data/ && wget https://huggingface.co/datasets/enio/TinyStories/resolve/main/TinyStories_pretokenized.tar.gz\n",
        "!cd ./llama2.c/data/TinyStories_all_data/ && tar -xvzf TinyStories_pretokenized.tar.gz"
      ],
      "metadata": {
        "id": "lCCtBUTocKZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change bfloat16 to float16 on line 72\n",
        "!sed -i \"72s/.*/dtype = 'float16'  # float32|bfloat16|float16/\" ./llama2.c/train.py"
      ],
      "metadata": {
        "id": "c6k6RMbCffO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# runtime 30s\n",
        "!cd llama2.c && python train.py --compile=False --eval_iters=10 --batch_size=8 --always_save_checkpoint=True --eval_interval=100 --max_iters=100 #--init_from='resume'"
      ],
      "metadata": {
        "id": "iGid6e3dHeAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ./llama2.c && make run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3v3qye4ZDJ9",
        "outputId": "0993359c-31f2-40e3-d9e2-0b35b4b2949e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gcc -O3 -o run run.c -lm\n",
            "gcc -O3 -o runq runq.c -lm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ./llama2.c/out && wget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories110M.bin\n",
        "!cd ./llama2.c && ./run /content/llama2.c/out/stories110M.bin -t 0.8 -n 256 -i \"Once upon a time \""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajZBfe6qbUja",
        "outputId": "ed54302f-5076-4a1b-fd7f-60c8048ed67f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time  a little girl was walking in the woods. She saw a little bunny hopping around. She wanted to pet the bunny, so she slowly moved closer.^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPkqUDO+jZbTUeSNzEabTw/"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}